{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make figures and tables for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "cohort = pd.read_csv(f'{data_dir}/cohort.csv')\n",
    "S_train = pd.read_csv(f'{data_dir}/S_train.csv')\n",
    "S_test = pd.read_csv(f'{data_dir}/S_test.csv')\n",
    "selection_criteria = pd.read_csv('helper_files/selection_criteria.csv')\n",
    "\n",
    "# get ids actually in data\n",
    "y_train = pd.read_csv(f'{data_dir}/experiment/60_all/y_train.csv', index_col=0)\n",
    "y_test = pd.read_csv(f'{data_dir}/experiment/60_all/y_test.csv', index_col=0)\n",
    "cohort_ids = pd.concat([y_train, y_test]).index\n",
    "cohort = cohort[cohort['ID'].isin(cohort_ids)]\n",
    "cohort = pd.merge(cohort, selection_criteria[['PATIENT_ID','HFRS']], left_on='ID', right_on='PATIENT_ID').drop('PATIENT_ID', axis=1)\n",
    "\n",
    "cohort['END_DSB'] = cohort['END_DSB'] / 365.25\n",
    "S = pd.concat([S_train, S_test])\n",
    "df = pd.merge(S, cohort, on='ID')\n",
    "\n",
    "var = [item for item in df.columns if item not in ['ID', 'train', 'CASE','END_DSB','HFRS']]\n",
    "n = pd.DataFrame(df.groupby(['train','CASE'])[var].sum())\n",
    "p = pd.DataFrame(df.groupby(['train','CASE'])[var].sum() / df.groupby(['train','CASE'])[var].count())\n",
    "p.columns = [f'{var} (%)' for var in p.columns]\n",
    "p = p * 100\n",
    "\n",
    "\n",
    "t_table = []\n",
    "for v in var:\n",
    "    t = pd.DataFrame(n.astype(int).astype(str)[v] + ' (' + p[f'{v} (%)'].round(decimals=1).astype(str) + '%)').T\n",
    "    t.index = [v]\n",
    "    t_table.append(t)\n",
    "\n",
    "t_table = pd.concat(t_table)\n",
    "t_table.to_clipboard()\n",
    "display(t_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cohort.groupby(['train','CASE'])['END_DSB'].mean().round(1).astype(str) + '+/-' + cohort.groupby(['train','CASE'])['END_DSB'].std().round(1).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cohort.groupby(['train','CASE'])['HFRS'].mean().round(1).astype(str) + '+/-' + cohort.groupby(['train','CASE'])['HFRS'].std().round(1).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort.groupby('train')['CASE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/lv-pick-rank-hals/rf_rank_eval.csv')\n",
    "\n",
    "def prep(df):\n",
    "    df['set'] = df['set'].str.replace('train', 'Train')\n",
    "    df['set'] = df['set'].str.replace('test', 'Validation')\n",
    "    df = df.rename(columns={\n",
    "        'set': 'Dataset', \n",
    "        'rank': 'Rank', \n",
    "        'f1' : 'F1',\n",
    "        'auc' : 'AUROC',\n",
    "        'auprc' : 'AUPRC'\n",
    "        })\n",
    "    return df\n",
    "\n",
    "df = prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "g = sns.lineplot(data=df, x='Rank', y='F1', hue='Dataset')\n",
    "g.figure.tight_layout()\n",
    "g.legend_.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxrx_phenotypes = pd.read_csv('data/phenotypes_50_dxrx_HALS-exact/phenotypes.csv')\n",
    "dxrx_time = pd.read_csv('data/phenotypes_50_dxrx_HALS-exact/time_factors.csv', index_col=0)\n",
    "lv_phenotypes = pd.read_csv('data/phenotypes_30_lv_HALS-exact/phenotypes.csv')\n",
    "lv_time = pd.read_csv('data/phenotypes_30_lv_HALS-exact/time_factors.csv', index_col=0)\n",
    "\n",
    "dxrx_time = dxrx_time.reset_index()\n",
    "dxrx_time = dxrx_time.rename(columns={'index': 'time'})\n",
    "dxrx_time['time'] = -dxrx_time['time'] / 2\n",
    "dxrx_time = dxrx_time.melt(id_vars='time', var_name='phenotype')\n",
    "dxrx_time['phenotype'] = dxrx_time['phenotype'].astype(int)\n",
    "\n",
    "lv_time = lv_time.reset_index()\n",
    "lv_time = lv_time.rename(columns={'index': 'time'})\n",
    "lv_time['time'] = -lv_time['time'] / 2\n",
    "lv_time = lv_time.melt(id_vars='time', var_name='phenotype')\n",
    "lv_time['phenotype'] = lv_time['phenotype'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dx/Rx phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "g = sns.lineplot(data=dxrx_time[dxrx_time['phenotype'] == n], x='time', y='value', color='black')\n",
    "g.figure.tight_layout()\n",
    "g.set_ylabel('')\n",
    "g.set_xlabel('Years before AMI onset')\n",
    "\n",
    "dxrx_phenotypes[dxrx_phenotypes['factor'] == n].sort_values('weight', ascending=False)[['feature','weight']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LV phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 19\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "g = sns.lineplot(data=lv_time[lv_time['phenotype'] == n], x='time', y='value', color='black')\n",
    "g.figure.tight_layout()\n",
    "g.set_ylabel('')\n",
    "g.set_xlabel('Years before AMI onset')\n",
    "\n",
    "lv_phenotypes[lv_phenotypes['factor'] == n].sort_values('weight', ascending=False)[['feature','weight']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pd.read_csv('tgfnn/cv_output/experiment_cv_results.csv')\n",
    "\n",
    "# replace abbreviations in model column of cv\n",
    "cv['model'] = cv['model'].replace({\n",
    "    # 'RF': 'Random Forest',\n",
    "    # 'LR': 'Logistic Regression',\n",
    "    # 'XGB': 'XGBoost',\n",
    "    'GFN': 'TGFNN'\n",
    "})\n",
    "\n",
    "cv['dataset'] = cv['dataset'].replace(\n",
    "    {\n",
    "        '30_phenotypes' : 'Phenotypes',\n",
    "        '30_aggregate' : 'Summary statistics',\n",
    "        '20_latest+demo' : 'Latest, demographics',\n",
    "        '30_latest+demo+phenotypes' : 'Latest, demo., phenotypes',\n",
    "        '20_latest+demo+aggregate' : 'Latest, demo., statistics',\n",
    "        '60_all' : 'All'\n",
    "    }\n",
    ")\n",
    "\n",
    "cv = cv.rename(\n",
    "    columns = {\n",
    "    'model' : 'Model',\n",
    "    'dataset' : 'Feature Set',\n",
    "    'roc_auc' : 'AUROC',\n",
    "    'auprc' : 'AUPRC',\n",
    "    'f1' : 'F1',\n",
    "    'precision' : 'Precision',\n",
    "    'recall' : 'Recall',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature set performance across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = cv[(cv['set'] == 'test')].groupby('Feature Set').mean().sort_values(by='F1', ascending=False).round(3).astype(str)\n",
    "stdvs = cv[(cv['set'] == 'test')].groupby('Feature Set').std().round(3).astype(str).reindex(means.index)\n",
    "(means + '±' + stdvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance across all feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = cv[(cv['set'] == 'test')].groupby('Model').mean().sort_values(by='F1', ascending=False).round(3).astype(str)\n",
    "stdvs = cv[(cv['set'] == 'test')].groupby('Model').std().round(3).astype(str).reindex(means.index)\n",
    "(means + '±' + stdvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean of all metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = cv.melt(id_vars=['Model', 'Feature Set','set'], value_vars=['AUROC', 'AUPRC', 'F1', 'Precision', 'Recall'])\n",
    "cv2[cv2['set'] == 'test'].groupby(['Model', 'Feature Set','set']).mean().reset_index().sort_values('value', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the best run of each model+feature set combination, according to F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv[cv['set'] == 'test'].loc[cv[cv['set'] == 'test'].groupby(['Model'])['AUROC'].idxmax().values,:].to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full table of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cv.groupby(['set','Feature Set','Model']).mean().round(3).astype(str) + '±' + cv.groupby(['set','Feature Set','Model']).std().round(3).astype(str)).to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(7,4)}, style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='test'], \n",
    "    x='Model', \n",
    "    y='AUROC', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "g.set_ylim(bottom=0.5, top=1)\n",
    "g.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(7,4)}, style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='test'], \n",
    "    x='Model', \n",
    "    y='F1', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "g.set_ylim(bottom=0, top=1)\n",
    "g.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(7,4)}, style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='test'], \n",
    "    x='Model', \n",
    "    y='AUPRC', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "g.set_ylim(bottom=0.3, top=1)\n",
    "g.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)  # Move the legend below the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(7,4)}, style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='test'], \n",
    "    x='Model', \n",
    "    y='Precision', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "g.set_ylim(bottom=0, top=1)\n",
    "g.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)  # Move the legend below the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(7,4)}, style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='test'], \n",
    "    x='Model', \n",
    "    y='Recall', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "g.set_ylim(bottom=0, top=1)\n",
    "g.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)  # Move the legend below the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='valid'], \n",
    "    x='Model', \n",
    "    y='F1', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "g.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=2)  # Move the legend below the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='train'], \n",
    "    x='Model', \n",
    "    y='AUROC', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='train'], \n",
    "    x='Model', \n",
    "    y='F1', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='train'], \n",
    "    x='Model', \n",
    "    y='AUPRC', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='train'], \n",
    "    x='Model', \n",
    "    y='Precision', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "g = sns.barplot(\n",
    "    data=cv[cv['set']=='train'], \n",
    "    x='Model', \n",
    "    y='Recall', \n",
    "    hue='Feature Set',\n",
    "    errorbar='sd',\n",
    "    palette='colorblind')\n",
    "sns.move_legend(g, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import kendalltau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_dir = 'cv_output'\n",
    "exp_name = 'experiment'\n",
    "feature_set = '60_all'\n",
    "X_train = pd.read_csv(f'data/{exp_name}/{feature_set}/X_train.csv', index_col=0)\n",
    "X_test = pd.read_csv(f'data/{exp_name}/{feature_set}/X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv(f'data/{exp_name}/{feature_set}/y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_LR_cv_models.pkl', 'rb'))\n",
    "rf_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_RF_cv_models.pkl', 'rb'))\n",
    "xgb_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_XGB_cv_models.pkl', 'rb'))\n",
    "tnet_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_TNET_cv_models.pkl', 'rb'))\n",
    "ebm_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_EBM_cv_models.pkl', 'rb'))\n",
    "\n",
    "model_lists = {\n",
    "    'LR' : lr_models,\n",
    "    'RF' : rf_models,\n",
    "    'XGB' : xgb_models,\n",
    "    'TNET' : tnet_models,\n",
    "    'EBM' : ebm_models\n",
    "}\n",
    "\n",
    "# compute feature importance\n",
    "fi_list = []\n",
    "for name, models in model_lists.items():\n",
    "\n",
    "    fi = []\n",
    "\n",
    "    for model in models:\n",
    "        if name == 'LR':\n",
    "            fi.append(abs(model.coef_[0]))\n",
    "        elif name == 'EBM':\n",
    "            data_dict = model.explain_global().data()\n",
    "            scores = np.array(model.explain_global().data()['scores'])[:len(X_test.columns.tolist())]\n",
    "            fi.append(scores)\n",
    "        else:\n",
    "            fi.append(model.feature_importances_)\n",
    "\n",
    "    fi = pd.DataFrame(fi, columns=X_train.columns)\n",
    "    fi['model'] = name\n",
    "    fi_list.append(fi)\n",
    "\n",
    "# combine feature importance and scale 0-1\n",
    "scaler = MinMaxScaler()\n",
    "all_fi = pd.concat(fi_list).set_index('model').T\n",
    "all_fi = pd.DataFrame(scaler.fit_transform(all_fi), index=all_fi.index, columns=all_fi.columns)\n",
    "all_fi = all_fi.T.reset_index()\n",
    "\n",
    "# add replicate index to model name\n",
    "repeated = np.tile(np.arange(5), 5)\n",
    "all_fi['model'] = all_fi['model'] + '_' + repeated.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = all_fi.melt(id_vars='model').groupby('variable')['value'].mean().sort_values(ascending=False)\n",
    "variable_to_id = {variable: i for i, variable in enumerate(means.index)}\n",
    "df_sorted = all_fi.melt(id_vars='model').sort_values(by='variable', key=lambda x: means[x], ascending=False)\n",
    "df_sorted['variable_id'] = df_sorted['variable'].map(variable_to_id)\n",
    "g = sns.lineplot(data=df_sorted, x='variable_id', y='value', color='black')\n",
    "g.set(xlabel='Rank', ylabel='Mean importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = all_fi.mean().sort_values(ascending=False).round(3).astype(str)\n",
    "stdvs = all_fi.std().round(3).astype(str).reindex(means.index)\n",
    "(means + '±' + stdvs).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kt = []\n",
    "\n",
    "for i in range(all_fi.shape[0]):\n",
    "    for j in range(all_fi.shape[0]):\n",
    "        x = all_fi.set_index('model').iloc[i,:].sort_values(ascending=False) #.head(20)\n",
    "        x_name = x.name\n",
    "        x = x.index.tolist()\n",
    "        y = all_fi.set_index('model').iloc[j,:].sort_values(ascending=False) #.head(20)\n",
    "        y_name = y.name\n",
    "        y = y.index.tolist()\n",
    "        corr, _ = kendalltau(x, y) \n",
    "        if i != j:\n",
    "            kt.append([x_name, y_name, corr])\n",
    "        else:\n",
    "            kt.append([x_name, y_name, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=0.85,style='white')\n",
    "g = sns.heatmap(pd.DataFrame(kt).pivot_table(index=0, columns=1, values=2), square=True, cmap='coolwarm', center=0, annot=False)\n",
    "g.set_xlabel(None)\n",
    "g.set_ylabel(None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_LR_cv_models.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = []\n",
    "for lr in lr_models:\n",
    "    fi.append(lr.coef_[0])\n",
    "\n",
    "fi = pd.DataFrame(fi, columns=X_train.columns)\n",
    "\n",
    "fi_table = fi.melt().groupby('variable')['value'].mean().round(3).astype(str) + '±' + fi.melt().groupby('variable')['value'].std().round(3).astype(str)\n",
    "sorted_f = fi.melt().groupby('variable')['value'].mean().abs().sort_values(ascending=False).index\n",
    "\n",
    "fi_table = fi_table[sorted_f]\n",
    "fi_table.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = fi.reset_index().melt(id_vars='index').groupby('variable')['value'].mean().sort_values(ascending=False)\n",
    "variable_to_id = {variable: i for i, variable in enumerate(means.index)}\n",
    "df_sorted = fi.reset_index().melt(id_vars='index').sort_values(by='variable', key=lambda x: means[x], ascending=False)\n",
    "df_sorted['variable_id'] = df_sorted['variable'].map(variable_to_id)\n",
    "g = sns.lineplot(data=df_sorted, x='variable_id', y='value')\n",
    "g.set(xlabel='Index', ylabel='Mean importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for col in X_test.columns.tolist():\n",
    "    if col.isdigit():\n",
    "        col = f'Dx/Rx phenotype {col}'\n",
    "    elif '_lv' in col:\n",
    "        col = f'Lab/vital phenotype {col.split(\"_\")[0]}'\n",
    "    elif '_dxrx' in col:\n",
    "        col = f'Dx/Rx phenotype {col.split(\"_\")[0]}'\n",
    "    elif col == 'max_BP_SYS':\n",
    "        col = 'Max systolic blood pressure'\n",
    "    elif col == 'mean_BP_DIA':\n",
    "        col = 'Mean diastolic blood pressure'\n",
    "    elif col == 'FAMILY_CARDIAC_HX':\n",
    "        col = 'Family history of cardiac diseases'\n",
    "    elif col == 'latest_SMOKING_STATUS_Never':\n",
    "        col = 'Latest smoking status: Never'\n",
    "    elif col == 'mean_BMI':\n",
    "        col = 'Mean body mass index'\n",
    "    elif col == 'min_BMI':\n",
    "        col = 'Min body mass index'\n",
    "    elif col == 'max_Mean Corpuscular Hgb':\n",
    "        col = 'Max mean corpuscular hemoglobin'\n",
    "    elif col == 'mean_TEMP':\n",
    "        col = 'Mean temperature'\n",
    "    elif col == 'mean_Glucose':\n",
    "        col = 'Mean glucose'\n",
    "    elif col == 'min_Creatinine':\n",
    "        col = 'Min creatinine'\n",
    "    \n",
    "    new_cols.append(col)\n",
    "\n",
    "\n",
    "shap_values = None\n",
    "\n",
    "for lr in lr_models:\n",
    "    explainer = shap.Explainer(lr, X_train, feature_names=X_train.columns)\n",
    "    if shap_values is None:\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "    else:\n",
    "        shap_values += explainer.shap_values(X_test)\n",
    "\n",
    "shap_values /= len(lr_models)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, max_display=10, feature_names=new_cols, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_RF_cv_models.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for col in X_test.columns.tolist():\n",
    "    if col.isdigit():\n",
    "        col = f'Dx/Rx phenotype {col}'\n",
    "    elif '_lv' in col:\n",
    "        col = f'Lab/vital phenotype {col.split(\"_\")[0]}'\n",
    "    elif '_dxrx' in col:\n",
    "        col = f'Dx/Rx phenotype {col.split(\"_\")[0]}'\n",
    "    elif col == 'max_BP_SYS':\n",
    "        col = 'Max systolic blood pressure'\n",
    "    elif col == 'FAMILY_CARDIAC_HX':\n",
    "        col = 'Family history of cardiac diseases'\n",
    "    elif col == 'latest_SMOKING_STATUS_Never':\n",
    "        col = 'Latest smoking status: Never'\n",
    "    \n",
    "    new_cols.append(col)\n",
    "\n",
    "\n",
    "shap_values = None\n",
    "\n",
    "for rf in rf_models:\n",
    "    explainer = shap.Explainer(rf)\n",
    "    if shap_values is None:\n",
    "        shap_values = explainer.shap_values(X_test)[1]\n",
    "    else:\n",
    "        shap_values += explainer.shap_values(X_test)[1]\n",
    "\n",
    "shap_values /= len(rf_models)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, max_display=10, feature_names=new_cols, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = []\n",
    "for rf in rf_models:\n",
    "    fi.append(rf.feature_importances_)\n",
    "\n",
    "fi = pd.DataFrame(fi, columns=X_train.columns)\n",
    "\n",
    "fi_table = fi.melt().groupby('variable')['value'].mean().round(3).astype(str) + '$\\pm$' + fi.melt().groupby('variable')['value'].std().round(3).astype(str)\n",
    "sorted_f = fi.melt().groupby('variable')['value'].mean().sort_values(ascending=False).index\n",
    "\n",
    "fi_table = fi_table[sorted_f]\n",
    "print(fi_table.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = fi.reset_index().melt(id_vars='index').groupby('variable')['value'].mean().sort_values(ascending=False)\n",
    "variable_to_id = {variable: i for i, variable in enumerate(means.index)}\n",
    "df_sorted = fi.reset_index().melt(id_vars='index').sort_values(by='variable', key=lambda x: means[x], ascending=False)\n",
    "df_sorted['variable_id'] = df_sorted['variable'].map(variable_to_id)\n",
    "g = sns.lineplot(data=df_sorted, x='variable_id', y='value')\n",
    "g.set(xlabel='Index', ylabel='Mean importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_DT_cv_models.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(\n",
    "    dt_models[0], \n",
    "    feature_names=X_train.columns,\n",
    "    filled=True,\n",
    "    out_file=None\n",
    "    ) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"DT\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_XGB_cv_models.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = []\n",
    "for xgb in xgb_models:\n",
    "    fi.append(xgb.feature_importances_)\n",
    "\n",
    "fi = pd.DataFrame(fi, columns=X_train.columns)\n",
    "\n",
    "fi_table = fi.melt().groupby('variable')['value'].mean().round(3).astype(str) + '$\\pm$' + fi.melt().groupby('variable')['value'].std().round(3).astype(str)\n",
    "sorted_f = fi.melt().groupby('variable')['value'].mean().sort_values(ascending=False).index\n",
    "\n",
    "fi_table = fi_table[sorted_f]\n",
    "fi_table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = fi.reset_index().melt(id_vars='index').groupby('variable')['value'].mean().sort_values(ascending=False)\n",
    "variable_to_id = {variable: i for i, variable in enumerate(means.index)}\n",
    "df_sorted = fi.reset_index().melt(id_vars='index').sort_values(by='variable', key=lambda x: means[x], ascending=False)\n",
    "df_sorted['variable_id'] = df_sorted['variable'].map(variable_to_id)\n",
    "g = sns.lineplot(data=df_sorted, x='variable_id', y='value')\n",
    "g.set(xlabel='Index', ylabel='Mean importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for col in X_test.columns.tolist():\n",
    "    if col.isdigit():\n",
    "        col = f'Dx/Rx phenotype {col}'\n",
    "    elif '_lv' in col:\n",
    "        col = f'Lab/vital phenotype {col.split(\"_\")[0]}'\n",
    "    elif '_dxrx' in col:\n",
    "        col = f'Dx/Rx phenotype {col.split(\"_\")[0]}'\n",
    "    elif col == 'max_BP_SYS':\n",
    "        col = 'Max systolic blood pressure'\n",
    "    elif col == 'FAMILY_CARDIAC_HX':\n",
    "        col = 'Family history of cardiac diseases'\n",
    "    elif col == 'latest_SMOKING_STATUS_Never':\n",
    "        col = 'Latest smoking status: Never'\n",
    "    elif col == 'mean_BMI':\n",
    "        col = 'Mean body mass index'\n",
    "    elif col == 'max_Mean Corpuscular Hgb':\n",
    "        col = 'Max mean corpuscular hemoglobin'\n",
    "    elif col == 'mean_TEMP':\n",
    "        col = 'Mean temperature'\n",
    "    \n",
    "    new_cols.append(col)\n",
    "\n",
    "\n",
    "shap_values = None\n",
    "\n",
    "for xgb in xgb_models:\n",
    "    explainer = shap.Explainer(xgb)\n",
    "    if shap_values is None:\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "    else:\n",
    "        shap_values += explainer.shap_values(X_test)\n",
    "\n",
    "shap_values /= len(xgb_models)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, max_display=10, feature_names=new_cols, show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnet_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_TNET_cv_models.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnet.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = []\n",
    "for tnet in tnet_models:\n",
    "    fi.append(tnet.feature_importances_)\n",
    "\n",
    "fi = pd.DataFrame(fi, columns=X_train.columns)\n",
    "\n",
    "fi_table = fi.melt().groupby('variable')['value'].mean().round(3).astype(str) + '±' + fi.melt().groupby('variable')['value'].std().round(3).astype(str)\n",
    "sorted_f = fi.melt().groupby('variable')['value'].mean().abs().sort_values(ascending=False).index\n",
    "\n",
    "fi_table = fi_table[sorted_f]\n",
    "fi_table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_EBM_cv_models.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = model.explain_global().data()\n",
    "scores = np.array(model.explain_global().data()['scores'])[:len(X_test.columns.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {f'feature_{i+1:04d}': col for i, col in enumerate(X_test.columns.tolist())} # map feature names\n",
    "\n",
    "fi = []\n",
    "for ebm in ebm_models:\n",
    "    data_dict = ebm.explain_global().data()\n",
    "    model_fi = pd.DataFrame([data_dict['names'], data_dict['scores']]).T\n",
    "    model_fi.columns = ['variable', 'importance']\n",
    "    model_fi['variable'] = model_fi['variable'].replace(feature_dict, regex=True)\n",
    "    fi.append(model_fi)\n",
    "\n",
    "merged_fi = pd.DataFrame(fi[0])\n",
    "for i in range(1, len(fi)):\n",
    "    merged_fi = pd.merge(merged_fi, fi[i], on='variable', suffixes=('', f'_{i+1}'), how='inner')\n",
    "\n",
    "fi = merged_fi.set_index('variable').T\n",
    "\n",
    "fi_table = fi.melt().groupby('variable')['value'].mean().round(3).astype(str) + '±' + fi.melt().groupby('variable')['value'].std().round(3).astype(str)\n",
    "sorted_f = fi.melt().groupby('variable')['value'].mean().abs().sort_values(ascending=False).index\n",
    "\n",
    "fi_table = fi_table[sorted_f]\n",
    "fi_table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_dir = 'cv_output'\n",
    "exp_name = 'experiment'\n",
    "feature_set = '60_all'\n",
    "X_train = pd.read_csv(f'data/{exp_name}/{feature_set}/X_train.csv', index_col=0)\n",
    "X_test = pd.read_csv(f'data/{exp_name}/{feature_set}/X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv(f'data/{exp_name}/{feature_set}/y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_confmats = []\n",
    "\n",
    "for model_name in ['DT','RF','LR','XGB','EBM','TNET','GFN']:\n",
    "    models = pickle.load(open(f'tgfnn/{mdl_dir}/exp_{exp_name}_{feature_set}_{model_name}_cv_models.pkl', 'rb'))\n",
    "\n",
    "    confmat = []\n",
    "    for model in models:\n",
    "        y_pred_test = model.predict(X_test.values)\n",
    "        confmat.append(confusion_matrix(y_test, y_pred_test) / y_test.shape[0])\n",
    "\n",
    "    confmat = np.array(confmat)\n",
    "    confmat = pd.DataFrame(np.mean(confmat, axis=0)).round(3).astype(str) + '+/-' + pd.DataFrame(np.std(confmat, axis=0)).round(3).astype(str)\n",
    "    all_confmats.append(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in all_confmats:\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ugotthis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
